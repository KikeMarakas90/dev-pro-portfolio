{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58690f49",
   "metadata": {},
   "source": [
    "# 01 – Generate Synthetic Data (Fabric Lakehouse)\n",
    "\n",
    "**Objetivo:** Generar dataset sintético y persistirlo en OneLake (Lakehouse) en formato Parquet.\n",
    "\n",
    "**Salida:** `/lakehouse/default/Files/raw/ops_daily.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "N_AGENTS = 60\n",
    "DAYS = 90\n",
    "\n",
    "agents = [f\"AG{str(i).zfill(3)}\" for i in range(1, N_AGENTS+1)]\n",
    "teams = [f\"T{(i%6)+1}\" for i in range(1, N_AGENTS+1)]\n",
    "dates = pd.date_range(end=pd.Timestamp.today().normalize(), periods=DAYS, freq='D')\n",
    "\n",
    "rows = []\n",
    "for a, t in zip(agents, teams):\n",
    "    base_prod = rng.normal(6.0, 1.0)\n",
    "    base_cases = rng.normal(18, 4)\n",
    "    stability = rng.uniform(0.05, 0.25)\n",
    "\n",
    "    for d in dates:\n",
    "        hrs = max(0.0, rng.normal(base_prod, base_prod*stability))\n",
    "        cases = max(0.0, rng.normal(base_cases, base_cases*stability))\n",
    "        rows.append((d.date().isoformat(), a, t, round(hrs,2), int(cases)))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"date\",\"agent_id\",\"team_id\",\"productive_hours\",\"cases_closed\"])\n",
    "\n",
    "output_path = \"/lakehouse/default/Files/raw/ops_daily.parquet\"\n",
    "df.to_parquet(output_path, index=False)\n",
    "print(f\"Wrote {len(df):,} rows to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
